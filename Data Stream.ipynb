{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling a Data Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TwitterStream class defined below is used to simulate a Twitter stream. It works the same way as a list, tuple or any other iterables that you may have worked with before --- you can loop over it to receive one tweet at a time. Each tweet may or may not contain emojis. There's also a helper function extract_emojis that helps you extract all emojis from a piece of text. It may be also useful to know that the variable UNICODE_EMOJI is a collection of all emojis that are circulating around the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "def extract_emojis(text):\n",
    "    \"\"\"\n",
    "    Extract all emojis from a str using regular expressions\n",
    "    \"\"\"\n",
    "    emoji_pattern = re.compile(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001F200-\\U0001F251\\u200D‚ôÇÔ∏è\\u200D‚ôÄÔ∏è]+')\n",
    "    return emoji_pattern.findall(text)\n",
    "\n",
    "class TwitterStream:\n",
    "    \"\"\"\n",
    "    Used to simulate a Twitter stream. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_file):\n",
    "        self.data_file = data_file\n",
    "        self.data = open(self.data_file, \"r\")\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.reset()\n",
    "    \n",
    "    def __next__(self):\n",
    "        next_line = self.data.readline()\n",
    "        if next_line:\n",
    "            return json.loads(next_line)[\"text\"]\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def __del__(self):\n",
    "        if not self.data.closed:\n",
    "            self.data.close()\n",
    "    \n",
    "    def reset(self):\n",
    "        if not self.data.closed:\n",
    "            self.data.close()\n",
    "        self.data = open(self.data_file, \"r\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from random import Random\n",
    "\n",
    "# Define HistPresvRandom\n",
    "class HistPresvRandom:\n",
    "    \"\"\"\n",
    "    History-preserving Random Number Generator\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=None):\n",
    "        self.prg = Random(seed)\n",
    "        self.hist = defaultdict(list)\n",
    "    \n",
    "    def random(self): # works exactly like random.random()\n",
    "        num = self.prg.random()\n",
    "        self.hist[\"random\"].append(num)\n",
    "        return num\n",
    "    \n",
    "    def sample(self, population): # works exactly like random.sample(population, 1)[0]\n",
    "        num = self.prg.sample(population, 1)[0]\n",
    "        self.hist[\"sample\"].append(num)\n",
    "        return num\n",
    "## Define random sampling algorithm\n",
    "class RandomSampler:\n",
    "    \n",
    "    def __init__(self, in_sample_prob, seed=None):\n",
    "        \n",
    "        self.in_sample_prob = in_sample_prob\n",
    "        self.random = HistPresvRandom(seed) # used whenever randomness is needed in your solution\n",
    "        self.sample, self.counts = list(), defaultdict(int) # recommended to use defaultdict, but an ordinary dict works fine too\n",
    "    \n",
    "    def _process_new_item(self, item):\n",
    "        \"\"\"\n",
    "        Applies random sampling to a newly arrived item\n",
    "        \"\"\"\n",
    "\n",
    "        if self.random.random() < self.in_sample_prob:\n",
    "            self.sample.append(item)\n",
    "            \n",
    "            for emoji in extract_emojis(item):\n",
    "                self.counts[emoji] += 1\n",
    "            \n",
    "      \n",
    "    \n",
    "    def do_sampling(self, stream):\n",
    "        \"\"\"\n",
    "        Iterates over a stream and performs random sampling\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sample.clear() # clear the existing sample\n",
    "        self.counts.clear() # clear the existing counts\n",
    "        \n",
    "        for item in stream:\n",
    "            # iterate over the stream\n",
    "            self._process_new_item(item)\n",
    "            \n",
    "            # returns a copy of sample and counts at the end of every iteration for grading - code given\n",
    "            yield self.sample.copy(), self.counts.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what the emoji distribution is after all tweets are processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ô∏è': 141, 'üòÇ': 34, 'ü•∫': 19, 'üòç': 16, 'üò≠': 15, 'üòä': 12, 'üòÇüòÇüòÇ': 11, 'ü§£': 10, 'üî•': 9, 'üò≠üò≠': 8, 'ü§î': 8, 'üòÇüòÇ': 7, 'üòÜ': 7, 'üíõ': 7, 'üëç': 7, 'üíï': 6, 'ü•∞': 6, 'üåü': 6, 'üòÅ': 6, 'üí¶': 6, 'üòé': 6, 'üò¢': 6, 'ü§≠': 6, 'üí™': 5, 'üòÇüòÇüòÇüòÇ': 5, 'ü¶ã': 5, 'üëá': 5, 'üôÑ': 5, 'üéâ': 5, 'üòÖ': 5, 'üòò': 4, 'üå∏': 4, 'üå∫': 4, 'üëè': 4, 'üíô': 4, 'üö®üö®': 4, 'üó£': 4, 'üò≥': 4, 'ü•≥': 4, 'üèÖ': 4, 'üòå': 3, 'üòî': 3, 'üèª': 3, 'üíù': 3, 'üò©': 3, 'üîÉ': 3, 'ü§æ\\u200d‚ôÇÔ∏è': 3, 'üçë': 3, 'üò∫': 3, 'üî•üî•': 3, 'ü§£ü§£': 3, 'üòà': 3, 'üëã': 3, 'üëÄ': 3, 'üíó': 3, 'üê∞': 3, 'üíñ': 3, 'üì±': 3, 'üò•': 3, 'üí≠': 3, 'üíö': 3, 'üê∂': 2, 'üíî': 2, 'üôå': 2, 'ü•¥': 2, 'üò°': 2, 'üò±üò±üò±': 2, 'üì¢': 2, 'üòÜüòÜ': 2, 'üñ§': 2, 'üíé': 2, 'üó£Ô∏è': 2, 'ü•µ': 2, 'üéÄ': 2, 'üîí': 2, 'üôÇ': 2, 'üëèüèª': 2, 'üôÉ': 2, 'üòá': 2, 'üòÉ': 2, 'ü•∫ü•∫ü•∫': 2, 'üëãüèª': 2, 'üôè': 2, 'ü§©': 2, 'üéà': 2, 'üòçüòç': 2, 'üí•': 2, 'üò¥': 2, 'üòÇü§£': 2, 'ü§®': 2, 'üëâ': 2, 'ü•∫ü•∫': 2, 'ü§£ü§£ü§£': 2, 'üò∑': 2, 'üéµ': 2, 'üôèüèæ': 2, 'ü•á': 2, 'üí†': 2, 'üí£': 2, 'üëèüëè': 2, 'üçí': 2, 'üéä': 2, 'üí¢': 2, 'üî¥': 2, 'üíÉ': 2, 'üôáüèª': 2, 'üåö': 2, 'üéÅ': 2, 'üíú': 2, 'üëâüèΩ': 2, '‚ôÇ': 2, 'üí´': 2, 'üîπ': 2, 'üî†': 2, 'üíòüíòüíò': 1, 'üòîüòî': 1, 'üòçüòçüòçüòçüòç': 1, 'üòôüòôüòô': 1, 'üôèüèª': 1, 'üëÜ': 1, 'ü•µü•µü•µü•µü§òüèªü§òüèªüôèüèªüôèüèª': 1, 'ü•±': 1, 'üíñüçë': 1, 'üé¥': 1, 'Ô∏èüë∞üèªüíê': 1, 'üî•üî•üî•üôåüèªüëèüèª': 1, 'üï∫': 1, 'üß†': 1, 'üòâ': 1, 'üò≠üò≠üò≠üò≠üò≠üò≠': 1, 'üòêüòêüòê': 1, 'üíå': 1, 'üíû': 1, 'üôèüëèüëèüëè': 1, 'üèÖüèÖüèÖüëëüëëüî•üî•': 1, 'üôèüòéüòâüí¶ü•∫': 1, 'ü§§': 1, 'ü§ç': 1, 'üòäü•∞': 1, 'üíª': 1, 'ü•∞ü•∞ü•∞': 1, 'üíóüíì': 1, 'üòçüíóüíì': 1, 'üíò': 1, 'üêï': 1, 'üê†': 1, 'ü¶Ä': 1, 'üôÖ\\u200d‚ôÄÔ∏è': 1, 'üçÇ': 1, 'üòáüòáüòá': 1, 'ü§£ü§£ü§£ü§£': 1, 'üíöü§≤üèΩ': 1, 'üòü': 1, 'ü§™': 1, 'üëéüòÇ': 1, 'ü•∫ü•∫üíï': 1, 'üòë': 1, 'üò©üò©üò©üò©üò©üò©': 1, 'üòéüòéüòé': 1, 'üëèüèæüëèüèæüëèüèæüëèüèæüëèüèæüëèüèæ': 1, 'üèΩüíú': 1, 'ü§ßüò≠üò≠üò£üò∞üò®üòØüò¢üò•üò•üò±üò±üò§üò§': 1, 'üñ§üñ§üñ§üñ§üñ§': 1, 'üòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇ': 1, 'üíîüíî': 1, 'üò∑üò∑üò∑üò∑üò∑üëçüëçüëçüëçüëç': 1, 'ü§ï': 1, 'üë©üèª\\u200düåæ': 1, 'üîó': 1, 'üëª': 1, 'üëèüèªüëèüèª': 1, 'üêù': 1, 'üòû': 1, 'Ô∏èüöÄüèê': 1, 'ü§¢ü•¥': 1, 'üö´üß¢': 1, 'üòÑüí¶': 1, 'üíöüíöüíöüíöüíöüíöüíöüíöüíöüíö': 1, 'üéäüéâüéâüéâüéâ': 1, 'üôá': 1, 'üêô': 1, 'üçõ': 1, 'üç∞': 1, 'üò≠üò≠üòÇüòÇ': 1, 'ü§Æ': 1, 'ü•∫üò±üòÇ': 1, 'üòê': 1, 'üòùüíï': 1, 'ü¶â': 1, 'ü§∑üèª\\u200d‚ôÄÔ∏è': 1, 'üôÑüòÖ': 1, 'üòöüòöüòö': 1, 'üôä': 1, 'üò≠üò≠üò≠': 1, 'üå∏üå±üçã': 1, 'üíúüíúüíú': 1, 'ü§°ü§°ü§°': 1, '‚ôÄ': 1, 'ü§™ü§™ü§™ü§™': 1, 'üòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇ': 1, 'üôèüôèüôèüí•': 1, 'ü§é': 1, 'üë£': 1, 'ü¶û': 1, 'üåπüíû': 1, 'ü§´ü§´ü§´': 1, 'üí∂': 1, 'üëáüèª': 1, 'üí™üí™üí™': 1, 'üèÉüèª\\u200d‚ôÄ': 1, 'ü§ê': 1, 'üòªüíï': 1, 'üìº': 1, 'üì£': 1, 'üòïüòÅ': 1, 'ü§£ü§£üíÄüíØ': 1, 'üë©üèΩ\\u200düç≥': 1, 'üò≠üòÇüòÇüíÄ': 1, 'ü•ã': 1, 'üò≠üíúüíõ': 1, 'Ô∏èüôã\\u200d‚ôÄÔ∏è': 1, 'üì•': 1, 'üëèüôå': 1, 'üåàüå∏': 1, 'üè¥': 1, 'ü•ãüóØÔ∏è': 1, 'ü§ôüèø': 1, 'üéÆ': 1, 'ü•ï': 1, 'üòâüèÉüèª\\u200d‚ôÄÔ∏èüèÉüèª\\u200d‚ôÄÔ∏èüèÉüèª\\u200d‚ôÄÔ∏è': 1, 'üòÇüíñüíñ': 1, 'üò≥üòÜ': 1, 'üî•üî•üî•üî•üî•üî•üî•üî•': 1, 'üòÖüòÖüòÖ': 1, 'üççüççüççüççüççüççüççüççüççüççüççüççüççüçç': 1, 'üôèüèΩ': 1, 'üôÉüôÉ': 1, 'üíÄüíÄ': 1, 'üîü': 1, 'üå†': 1, 'üòö': 1, 'üèº': 1, 'üòãüòã': 1, 'ü§¶üèΩ\\u200d‚ôÄÔ∏è': 1, 'üò†üò°üò∑üôÑüëáüôÑ': 1, 'üò≥üò≥üò≥': 1, 'üê∞üíñ': 1, 'üíÄüíÄüíÄüíÄüòÇüòÇüòÇüòÇüòÇüòÇ': 1, 'üôÇüôÇ': 1, 'Ô∏èüíìüíìü§©ü•∞ü•∞ü•∞': 1, 'üôÑü§≠': 1, 'üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠': 1, 'üé§': 1, 'üëèüèº': 1, 'üòçüî•': 1, 'üòÇüòÇüòÇüòÇüòÇüòÇ': 1, '‚ôÄÔ∏è': 1, 'ü•∞üíô': 1, 'üëØ\\u200d‚ôÇÔ∏è': 1, 'üòÖüòÖüòÖüòéü¶†ü§£üëç': 1, 'ü§ôüèª': 1, 'üíúüíúüíúüíúüíúüíúüíú': 1, 'ü§¶üèª\\u200d‚ôÇÔ∏è': 1, 'üôèüèΩüôèüèΩ': 1, 'üòÜüëçÔ∏è': 1, 'üôÜüèª\\u200d‚ôÇÔ∏è': 1, 'üòÑüòÑüòÑ': 1, 'üåù': 1, 'üëâüëà': 1, 'ü§£ü§£üòÇ': 1, 'üßü\\u200d‚ôÄÔ∏è': 1, 'üê®üê®üê®': 1, 'üê®üéÅ': 1, 'üò©üò©': 1, 'üò≤': 1, 'ü§û': 1, 'üëáüëáüëáüëá': 1, 'üôåüèªüôèüèª': 1, 'üê∑': 1, 'ü§£üò≠ü§£üò≠ü§£üò≠': 1, 'ü•∫üôä': 1, 'üåå': 1, 'üòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇ': 1, 'üòÇü§£üòπ': 1, 'üí∞': 1, 'üòòüòò': 1, 'üôèüèæüôåüèæ': 1, 'üòúüòú': 1, 'üòí': 1, 'üê¥': 1, 'üòÇüòÇüòÇüòÇüòéüòéüòéüòÇüòÇ': 1, 'üëçüëçüòéüòÇüòÇ': 1, 'üíóüíó': 1, 'Ô∏èüíñüíù': 1, 'üçª': 1, 'üí∞üí∞': 1, 'üëèüèΩüëèüèΩüëèüèΩ': 1, 'üëéüèΩüòïüôà': 1, 'üòàüé∂': 1, 'üîû': 1, 'üõë': 1, 'üòÇüòÇüíñ': 1, 'üíñü§©ü§∞': 1, 'üò¨': 1, 'üòÇüòÇü§£ü§£': 1, 'ü§öüèæ': 1, 'Ô∏èüêë': 1, 'üíß': 1, 'üò±': 1, 'ü§∑\\u200d‚ôÄÔ∏è': 1, 'üòπ': 1, 'üòù': 1, 'üë©\\u200d': 1, 'Ô∏è\\u200düë®üíì': 1, 'üåà': 1, 'ü¶†': 1, 'üö´': 1, 'üòåüòå': 1, 'üåπ': 1, 'ü•à': 1, 'ü•â': 1, 'üò¢üò¢üò¢üò¢': 1, 'ü§¨': 1, 'ü§§ü§§ü§§': 1, 'üç´': 1, 'üò§': 1, 'üå∑üê®üå∑': 1, 'üò¢üå±': 1, 'üòÄüòÄüòÄ': 1, 'üçªü§ôüèª': 1, 'üòçüíúüíö': 1, 'üëå': 1, 'üç£': 1, 'üê∏üòé': 1, 'üî•üí™': 1, 'üò≤üíïüíï': 1, 'üòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇ': 1, 'üî•ü•≥': 1, 'üååüåæüßöüèª\\u200d‚ôÄÔ∏è': 1, 'üò≥üòÇ': 1, 'üö∂': 1, 'üëçüëçüëç': 1, 'üòÜü§£': 1, 'üòÖü§£ü§£üòÇüòÖü§£': 1, 'ü§üüèª': 1, 'ü§§ü•µ': 1, 'ü§≠üíéüéÄüò≥': 1, 'üíïüíïüíï': 1, 'ü•∫üò≠üíî': 1, 'üë®\\u200düë©\\u200düëß\\u200düëß': 1, 'üòú': 1, 'ü§∑üèº\\u200d‚ôÄÔ∏èü§≠': 1, 'üò¢üò¢': 1, 'üßê': 1, 'üì∏üéû': 1, 'üö®': 1, 'üîÅ': 1, 'üôèüôèüôèüôèüôèüôèüôèüôèüôè': 1, 'üòÇüòÇüòÇüòÇüòå': 1, 'üçäüçä': 1, 'üëèüëèüôèüôè': 1, 'Ô∏èüôåüèΩ': 1, 'üò≥üôÅüòÖüòÖ': 1, 'üòîüò≠üòîüò≠': 1, 'üò™': 1, 'üìç': 1, 'üé∏üé∏ü•Åü•Å': 1, 'üñ§üñ§': 1, 'üò≠üò≠üò≠üíõ': 1, 'üõå': 1, 'üí£üí£üí£': 1, 'üëçüòè': 1, 'üëëüíõ': 1, 'üò≥üò≥': 1, 'üòã': 1, 'üëçüëçüí™üí™üò§üò§': 1, 'üíéüíç': 1, 'üíçüíé': 1, 'üêø': 1, 'ü§™ü§ûüèª': 1, 'ü•∞ü•∞': 1, 'üòàüòàüòà': 1, 'üíïüòç': 1, 'üêê': 1, 'üòó': 1, 'üèΩ': 1, 'üòÉüëçüèª': 1, 'üåô': 1, 'üî•üî•üî•üî•üî•üî•': 1, 'üçá': 1, 'Ô∏èü•∞': 1, 'ü§¶üèæ\\u200d‚ôÇÔ∏èü§¶üèæ\\u200d‚ôÇÔ∏èü§¶üèæ\\u200d‚ôÇÔ∏è': 1, 'üòÇüòÇüò≠üò≠': 1, 'ü§ì': 1, 'üòÇüòÇüòÇüò≠': 1, 'üíªüì≤': 1, 'ü§£üòâ': 1, 'üòàüßü': 1, 'üî¥üî¥': 1, 'üåπüåπüåπüåπ': 1, 'üëäüëäüëä': 1, 'üëçüëçüëçüëçüëçüëçüôèüôèüôè': 1, 'üèªüôåüèª': 1, 'ü§≠ü§≠ü§≠': 1, 'üè≥Ô∏è\\u200düåà': 1, 'üòÇüòπüòπüòπüòπüòπüòπüòπüòπ': 1, 'üí™üí™': 1, 'Ô∏èüôèüèª': 1, 'ü•Ç': 1, 'üêæ': 1, 'üíïüê¨üíïüê¨üíïüê¨üíïüê¨üíïüê¨üíï': 1, 'üòÇüòÇüòÇü§¶üèæ\\u200d‚ôÇÔ∏è': 1, 'üòõ': 1, 'üîµ': 1, 'ü§îüòÇ': 1, 'üê∂üçëüê∞': 1, 'üò§üò©': 1, 'üòçüòä': 1, 'üíØ': 1, 'üëåüèΩ': 1, 'üòÖüòÖüòÖüòÖ': 1, 'üèÜ': 1, 'ü§£ü§£ü§£ü§£ü§£ü§£ü§£': 1, 'üëèüëèüëè': 1, 'üò≠üíú': 1, 'ü§∑\\u200d‚ôÄÔ∏èü§∑\\u200d‚ôÄÔ∏èü§∑\\u200d‚ôÄÔ∏èü§∑\\u200d‚ôÄÔ∏èü§∑\\u200d‚ôÄÔ∏è': 1, 'üåπüíô': 1, 'ü§ü': 1, 'üíôüíôüíôüíôüíô': 1, 'üêØ': 1, 'üë§': 1, 'üôÇüíÅüèª\\u200d‚ôÄÔ∏è': 1}\n"
     ]
    }
   ],
   "source": [
    "in_sample_prob, seed = 0.1, 42\n",
    "ran_emo = RandomSampler(in_sample_prob, seed)\n",
    "\n",
    "# Do sampling. Don't have to collect the results. Just exhaust the stream\n",
    "for _ in ran_emo.do_sampling(TwitterStream(\"Data/tweets\")):\n",
    "    pass\n",
    "\n",
    "sorted_counts = {emoji: ran_emo.counts[emoji] for emoji in sorted(ran_emo.counts.keys(), key=ran_emo.counts.get, reverse=True)}\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservior Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class ReservoirSampler:\n",
    "    \n",
    "    def __init__(self, sample_size, seed=None):\n",
    "        \n",
    "        self.sample_size = sample_size\n",
    "        self.random = HistPresvRandom(seed) # used whenever randomness is needed in your solution\n",
    "        self.sample, self.counts = list(), defaultdict(int)\n",
    "    \n",
    "    def _process_new_item(self, item, index):\n",
    "        \"\"\"\n",
    "        Decides whether a new item should be added to the sample and adjusts the counts accordingly\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        prob = self.sample_size / (index + 1)\n",
    "        \n",
    "        if self.random.random() <= prob:\n",
    "            idx_to_remove = self.random.sample(range(self.sample_size))\n",
    "            removed_item = self.sample.pop(idx_to_remove)\n",
    "            \n",
    "            for emoji in extract_emojis(removed_item):\n",
    "                self.counts[emoji] -= 1\n",
    "                if self.counts[emoji] <= 0:\n",
    "                    del self.counts[emoji]\n",
    "            self.sample.append(item)\n",
    "            \n",
    "            for emoji in extract_emojis(item):\n",
    "                self.counts[emoji] += 1\n",
    "     \n",
    "    \n",
    "    def do_sampling(self, stream):\n",
    "        \"\"\"\n",
    "        Iterates over a stream and performs reservoir sampling\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sample.clear() # clear the existing sample\n",
    "        self.counts.clear() # clear the existing counts\n",
    "        \n",
    "        for index, item in enumerate(stream): # iterate over the stream\n",
    "\n",
    "            \n",
    "            \n",
    "            if index < self.sample_size:\n",
    "                self.sample.append(item)\n",
    "                for emoji in extract_emojis(item):\n",
    "                    self.counts[emoji] += 1\n",
    "            else:\n",
    "                self._process_new_item(item, index)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            # returns a copy of sample and counts at the end of every iteration for grading - code given\n",
    "            yield self.sample.copy(), self.counts.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the emoji distribution is after all tweets processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ô∏è': 14, 'üíô': 7, 'üòÇ': 4, 'ü•∞ü•∞ü•∞ü•∞': 3, 'üò≠üò≠': 3, 'üëç': 2, 'üòç': 2, 'üëë': 2, 'üíï': 1, 'üòè': 1, 'üé∂': 1, 'üòòüòò': 1, 'Ô∏èüéµ': 1, 'ü•∫ü•∫ü•∫ü•∫ü•∫ü•∞ü•∞ü•∞ü•∞ü•∞üò≠üò≠üò≠': 1, 'üò≠üò≠üò≠üò≠': 1, 'üêü': 1, 'üê∞': 1, 'üë´': 1, 'üë©\\u200d': 1, 'Ô∏è\\u200düíã\\u200düë©': 1, 'üòà': 1, 'ü•∞üíöüèÄüèàüé§': 1, 'üò†': 1, 'üôÉüôÉ': 1, 'üåà': 1, 'üòãüòã': 1, 'üèº': 1, 'üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠üò≠': 1, 'üò∑': 1, 'ü§¶üèª\\u200d‚ôÇÔ∏è': 1, 'üòÇüòÇüòÇüòÇ': 1, 'ü§ì': 1, 'ü§∑üèø\\u200d‚ôÇÔ∏è': 1, 'üî•': 1, 'üê≥': 1, 'üí∞': 1, 'ü•á': 1, 'üëèüî•': 1, 'üëâ': 1, 'üèÜüèÜüèÜ': 1, 'ü¶æ': 1, 'üòû': 1, 'üíôüì∏': 1, 'ü§ë': 1, 'üôèüèæ': 1, 'Ô∏èüòçüôÜüèΩ\\u200d‚ôÇÔ∏è': 1, 'üç™': 1, 'üòá': 1, 'üòâ': 1, 'ü•¥': 1, 'üò©': 1, 'üèØ': 1, 'ü¶Ö': 1, 'üò±': 1, 'üòì': 1, 'üëá': 1, 'ü§ó': 1, 'ü•∫üíì': 1, 'üòçüòçüòçüòç': 1, 'üò§üò©': 1, 'üò≠üê±üê•üçºüíï': 1, 'üò™ü•∫': 1}\n"
     ]
    }
   ],
   "source": [
    "sample_size, seed = 100, 0\n",
    "stu_ans = ReservoirSampler(sample_size, seed)\n",
    "\n",
    "# Do sampling. Don't have to collect the results. Just exhaust the stream\n",
    "for _ in stu_ans.do_sampling(TwitterStream(\"Data/tweets\")):\n",
    "    pass\n",
    "\n",
    "sorted_counts = {emoji: stu_ans.counts[emoji] for emoji in sorted(stu_ans.counts.keys(), key=stu_ans.counts.get, reverse=True)}\n",
    "print(sorted_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
